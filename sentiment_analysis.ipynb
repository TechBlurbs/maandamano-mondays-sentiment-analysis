{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maandamano Mondays Sentiment Analysis Report\n",
    "\n",
    "This notebook provides a comprehensive analysis of sentiment data from the Maandamano Mondays protests in Kenya, including exploratory data analysis (EDA), visualizations, and insights into public sentiment and economic implications.\n",
    "\n",
    "## Objectives\n",
    "- Analyze sentiment distribution across protest-related tweets\n",
    "- Perform exploratory data analysis to gain insights into customer sentiment\n",
    "- Visualize results and provide clear, concise reporting\n",
    "- Assess economic implications of public sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled sentiment data\n",
    "df = pd.read_csv('data/labeled_tweets.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse sentiment labels\n",
    "def parse_sentiment_labels(label_string):\n",
    "    \"\"\"Parse sentiment label string into probabilities.\"\"\"\n",
    "    try:\n",
    "        # Remove brackets and split by whitespace\n",
    "        label_string = label_string.strip('[]')\n",
    "        values = label_string.split()\n",
    "        return [float(val) for val in values]\n",
    "    except:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n",
    "def get_sentiment_class(probabilities):\n",
    "    \"\"\"Get sentiment class from probabilities [negative, neutral, positive].\"\"\"\n",
    "    if not probabilities or len(probabilities) != 3:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    max_idx = probabilities.index(max(probabilities))\n",
    "    classes = [\"negative\", \"neutral\", \"positive\"]\n",
    "    return classes[max_idx]\n",
    "\n",
    "# Parse sentiment labels and add columns\n",
    "df['label_probabilities'] = df['labels'].apply(parse_sentiment_labels)\n",
    "df['sentiment'] = df['label_probabilities'].apply(get_sentiment_class)\n",
    "df['confidence'] = df['label_probabilities'].apply(lambda x: max(x) if x else 0)\n",
    "df['negative_score'] = df['label_probabilities'].apply(lambda x: x[0] if len(x) > 0 else 0)\n",
    "df['neutral_score'] = df['label_probabilities'].apply(lambda x: x[1] if len(x) > 1 else 0)\n",
    "df['positive_score'] = df['label_probabilities'].apply(lambda x: x[2] if len(x) > 2 else 0)\n",
    "\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(f\"\\nAverage confidence score: {df['confidence'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Total tweets analyzed: {len(df)}\")\n",
    "print(f\"Unique users: {df['username'].nunique()}\")\n",
    "print(f\"Date range: {df.index.min() if len(df) > 0 else 'N/A'} to {df.index.max() if len(df) > 0 else 'N/A'}\")\n",
    "print(f\"Average confidence score: {df['confidence'].mean():.3f}\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Pie chart of sentiment distribution\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "axes[0, 0].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart of sentiment distribution\n",
    "sentiment_counts.plot(kind='bar', ax=axes[0, 1], color=['red', 'gray', 'green'])\n",
    "axes[0, 1].set_title('Sentiment Counts', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Sentiment')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Confidence score distribution\n",
    "axes[1, 0].hist(df['confidence'], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[1, 0].set_title('Confidence Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Confidence Score')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Sentiment scores comparison\n",
    "sentiment_scores = df[['negative_score', 'neutral_score', 'positive_score']]\n",
    "sentiment_scores.boxplot(ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Sentiment Score Distributions', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key statistics\n",
    "print(\"\\nKey Findings:\")\n",
    "total_tweets = len(df)\n",
    "neg_pct = (sentiment_counts.get('negative', 0) / total_tweets) * 100\n",
    "neu_pct = (sentiment_counts.get('neutral', 0) / total_tweets) * 100\n",
    "pos_pct = (sentiment_counts.get('positive', 0) / total_tweets) * 100\n",
    "\n",
    "print(f\"‚Ä¢ Negative sentiment: {neg_pct:.1f}% ({sentiment_counts.get('negative', 0)} tweets)\")\n",
    "print(f\"‚Ä¢ Neutral sentiment: {neu_pct:.1f}% ({sentiment_counts.get('neutral', 0)} tweets)\")\n",
    "print(f\"‚Ä¢ Positive sentiment: {pos_pct:.1f}% ({sentiment_counts.get('positive', 0)} tweets)\")\n",
    "\n",
    "if neg_pct > 50:\n",
    "    print(f\"\\n‚ö†Ô∏è  ALERT: Negative sentiment dominates ({neg_pct:.1f}%), indicating HIGH public concern\")\n",
    "elif pos_pct > 50:\n",
    "    print(f\"\\n‚úÖ Positive sentiment dominates ({pos_pct:.1f}%), indicating favorable public opinion\")\n",
    "else:\n",
    "    print(f\"\\nüìä Mixed sentiment distribution suggests divided public opinion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hashtag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashtag sentiment analysis\n",
    "hashtag_sentiment = defaultdict(lambda: {\"negative\": 0, \"neutral\": 0, \"positive\": 0})\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    sentiment = row['sentiment']\n",
    "    hashtags_text = row.get('extract_hashtags', '')\n",
    "    hashtags = hashtags_text.split() if hashtags_text else []\n",
    "    \n",
    "    for hashtag in hashtags:\n",
    "        hashtag_sentiment[hashtag][sentiment] += 1\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "hashtag_data = []\n",
    "for hashtag, sentiments in hashtag_sentiment.items():\n",
    "    total = sum(sentiments.values())\n",
    "    if total >= 5:  # Filter hashtags with at least 5 mentions\n",
    "        hashtag_data.append({\n",
    "            'hashtag': hashtag,\n",
    "            'total': total,\n",
    "            'negative': sentiments['negative'],\n",
    "            'neutral': sentiments['neutral'],\n",
    "            'positive': sentiments['positive'],\n",
    "            'neg_pct': (sentiments['negative'] / total) * 100,\n",
    "            'neu_pct': (sentiments['neutral'] / total) * 100,\n",
    "            'pos_pct': (sentiments['positive'] / total) * 100\n",
    "        })\n",
    "\n",
    "hashtag_df = pd.DataFrame(hashtag_data).sort_values('total', ascending=False)\n",
    "\n",
    "# Visualize top hashtags\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "# Top hashtags by volume\n",
    "top_hashtags = hashtag_df.head(10)\n",
    "axes[0].bar(range(len(top_hashtags)), top_hashtags['total'], color='skyblue')\n",
    "axes[0].set_xticks(range(len(top_hashtags)))\n",
    "axes[0].set_xticklabels([f\"#{tag}\" for tag in top_hashtags['hashtag']], rotation=45, ha='right')\n",
    "axes[0].set_title('Top 10 Hashtags by Volume', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Mentions')\n",
    "\n",
    "# Sentiment breakdown for top hashtags\n",
    "x = range(len(top_hashtags))\n",
    "width = 0.25\n",
    "\n",
    "axes[1].bar([i - width for i in x], top_hashtags['negative'], width, label='Negative', color='red', alpha=0.7)\n",
    "axes[1].bar(x, top_hashtags['neutral'], width, label='Neutral', color='gray', alpha=0.7)\n",
    "axes[1].bar([i + width for i in x], top_hashtags['positive'], width, label='Positive', color='green', alpha=0.7)\n",
    "\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([f\"#{tag}\" for tag in top_hashtags['hashtag']], rotation=45, ha='right')\n",
    "axes[1].set_title('Sentiment Breakdown for Top Hashtags', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Hashtags with Sentiment Analysis:\")\n",
    "for _, row in top_hashtags.iterrows():\n",
    "    print(f\"#{row['hashtag']}: Neg:{row['neg_pct']:.1f}% Neu:{row['neu_pct']:.1f}% Pos:{row['pos_pct']:.1f}% (n={row['total']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. User Engagement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User engagement patterns\n",
    "user_stats = df.groupby('username').agg({\n",
    "    'sentiment': ['count', lambda x: (x == 'negative').sum(), \n",
    "                  lambda x: (x == 'neutral').sum(), \n",
    "                  lambda x: (x == 'positive').sum()],\n",
    "    'confidence': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "user_stats.columns = ['total_tweets', 'negative_tweets', 'neutral_tweets', 'positive_tweets', 'avg_confidence']\n",
    "user_stats = user_stats.reset_index()\n",
    "user_stats['engagement_score'] = user_stats['total_tweets'] * user_stats['avg_confidence']\n",
    "\n",
    "# Most active users\n",
    "top_users = user_stats.nlargest(10, 'total_tweets')\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "# Most active users\n",
    "axes[0].bar(range(len(top_users)), top_users['total_tweets'], color='lightcoral')\n",
    "axes[0].set_xticks(range(len(top_users)))\n",
    "axes[0].set_xticklabels([f\"@{user}\" for user in top_users['username']], rotation=45, ha='right')\n",
    "axes[0].set_title('Most Active Users (by Tweet Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Tweets')\n",
    "\n",
    "# User sentiment patterns\n",
    "x = range(len(top_users))\n",
    "width = 0.25\n",
    "\n",
    "axes[1].bar([i - width for i in x], top_users['negative_tweets'], width, label='Negative', color='red', alpha=0.7)\n",
    "axes[1].bar(x, top_users['neutral_tweets'], width, label='Neutral', color='gray', alpha=0.7)\n",
    "axes[1].bar([i + width for i in x], top_users['positive_tweets'], width, label='Positive', color='green', alpha=0.7)\n",
    "\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([f\"@{user}\" for user in top_users['username']], rotation=45, ha='right')\n",
    "axes[1].set_title('Sentiment Distribution for Most Active Users', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Tweet Count')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nUser Engagement Statistics:\")\n",
    "print(f\"Total unique users: {len(user_stats)}\")\n",
    "print(f\"Users with multiple tweets: {len(user_stats[user_stats['total_tweets'] > 1])}\")\n",
    "print(f\"Average tweets per user: {user_stats['total_tweets'].mean():.2f}\")\n",
    "print(f\"Most active user: @{top_users.iloc[0]['username']} ({top_users.iloc[0]['total_tweets']} tweets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Analysis and Key Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pattern analysis by sentiment\n",
    "from collections import Counter\n",
    "\n",
    "sentiment_texts = df.groupby('sentiment')['lemmatized_text'].apply(list).to_dict()\n",
    "\n",
    "# Extract key terms for each sentiment\n",
    "sentiment_words = {}\n",
    "for sentiment, texts in sentiment_texts.items():\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        if pd.notna(text):\n",
    "            words = str(text).lower().split()\n",
    "            for word in words:\n",
    "                if len(word) > 3 and word.isalpha():  # Filter short words and non-alphabetic\n",
    "                    word_counts[word] += 1\n",
    "    sentiment_words[sentiment] = word_counts\n",
    "\n",
    "# Visualize top words by sentiment\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "sentiments = ['negative', 'neutral', 'positive']\n",
    "colors = ['red', 'gray', 'green']\n",
    "\n",
    "for i, (sentiment, color) in enumerate(zip(sentiments, colors)):\n",
    "    if sentiment in sentiment_words:\n",
    "        top_words = dict(sentiment_words[sentiment].most_common(10))\n",
    "        words = list(top_words.keys())\n",
    "        counts = list(top_words.values())\n",
    "        \n",
    "        axes[i].barh(words, counts, color=color, alpha=0.7)\n",
    "        axes[i].set_title(f'Top Words - {sentiment.capitalize()}', fontsize=12, fontweight='bold')\n",
    "        axes[i].set_xlabel('Frequency')\n",
    "        axes[i].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key terms analysis\n",
    "print(\"\\nKey Terms Analysis:\")\n",
    "for sentiment in sentiments:\n",
    "    if sentiment in sentiment_words:\n",
    "        print(f\"\\n{sentiment.upper()} sentiment top words:\")\n",
    "        for word, count in sentiment_words[sentiment].most_common(10):\n",
    "            print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Economic Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Economic impact keywords analysis\n",
    "business_keywords = ['business', 'shop', 'duka', 'economy', 'money', 'work', 'job', 'income', 'trade', 'market']\n",
    "economic_keywords = ['cost', 'price', 'expensive', 'cheap', 'afford', 'salary', 'pay', 'buy', 'sell']\n",
    "protest_impact_keywords = ['close', 'closed', 'shutdown', 'block', 'blocked', 'stop', 'stopped', 'cancel']\n",
    "\n",
    "def count_keywords(text, keywords):\n",
    "    \"\"\"Count occurrences of keywords in text.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text_lower = str(text).lower()\n",
    "    return sum(1 for keyword in keywords if keyword in text_lower)\n",
    "\n",
    "# Add economic impact columns\n",
    "df['business_mentions'] = df['lemmatized_text'].apply(lambda x: count_keywords(x, business_keywords))\n",
    "df['economic_mentions'] = df['lemmatized_text'].apply(lambda x: count_keywords(x, economic_keywords))\n",
    "df['protest_impact_mentions'] = df['lemmatized_text'].apply(lambda x: count_keywords(x, protest_impact_keywords))\n",
    "df['total_economic_mentions'] = df['business_mentions'] + df['economic_mentions'] + df['protest_impact_mentions']\n",
    "\n",
    "# Economic impact by sentiment\n",
    "economic_sentiment = df[df['total_economic_mentions'] > 0].groupby('sentiment').agg({\n",
    "    'total_economic_mentions': ['count', 'sum'],\n",
    "    'business_mentions': 'sum',\n",
    "    'economic_mentions': 'sum',\n",
    "    'protest_impact_mentions': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "economic_sentiment.columns = ['economic_tweets', 'total_mentions', 'business_mentions', 'economic_mentions', 'protest_impact_mentions']\n",
    "\n",
    "# Visualize economic impact\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Economic mentions by sentiment\n",
    "if not economic_sentiment.empty:\n",
    "    economic_sentiment['economic_tweets'].plot(kind='bar', ax=axes[0, 0], color=['red', 'gray', 'green'])\n",
    "    axes[0, 0].set_title('Economic-Related Tweets by Sentiment', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Number of Tweets')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Business impact distribution\n",
    "business_tweets = df[df['business_mentions'] > 0]\n",
    "if not business_tweets.empty:\n",
    "    business_tweets['sentiment'].value_counts().plot(kind='pie', ax=axes[0, 1], autopct='%1.1f%%')\n",
    "    axes[0, 1].set_title('Business-Related Tweets Sentiment', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Economic keyword frequency\n",
    "keyword_data = {\n",
    "    'Business': df['business_mentions'].sum(),\n",
    "    'Economic': df['economic_mentions'].sum(),\n",
    "    'Protest Impact': df['protest_impact_mentions'].sum()\n",
    "}\n",
    "\n",
    "axes[1, 0].bar(keyword_data.keys(), keyword_data.values(), color=['blue', 'orange', 'purple'], alpha=0.7)\n",
    "axes[1, 0].set_title('Economic Keyword Categories', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Total Mentions')\n",
    "\n",
    "# Sentiment vs Economic Impact\n",
    "sentiment_economic = df.groupby('sentiment')['total_economic_mentions'].sum()\n",
    "if not sentiment_economic.empty:\n",
    "    sentiment_economic.plot(kind='bar', ax=axes[1, 1], color=['red', 'gray', 'green'])\n",
    "    axes[1, 1].set_title('Total Economic Mentions by Sentiment', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Total Mentions')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Economic impact statistics\n",
    "total_tweets_with_economic = len(df[df['total_economic_mentions'] > 0])\n",
    "economic_percentage = (total_tweets_with_economic / len(df)) * 100\n",
    "\n",
    "print(\"\\nEconomic Impact Analysis:\")\n",
    "print(f\"Tweets mentioning economic terms: {total_tweets_with_economic} ({economic_percentage:.1f}%)\")\n",
    "print(f\"Business-related mentions: {df['business_mentions'].sum()}\")\n",
    "print(f\"Economic-related mentions: {df['economic_mentions'].sum()}\")\n",
    "print(f\"Protest impact mentions: {df['protest_impact_mentions'].sum()}\")\n",
    "\n",
    "if not economic_sentiment.empty:\n",
    "    print(\"\\nEconomic sentiment breakdown:\")\n",
    "    for sentiment, row in economic_sentiment.iterrows():\n",
    "        print(f\"{sentiment.capitalize()}: {row['economic_tweets']} tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Findings and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"    MAANDAMANO MONDAYS SENTIMENT ANALYSIS REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dataset overview\n",
    "print(\"\\nüìä DATASET OVERVIEW:\")\n",
    "print(f\"‚Ä¢ Total analyzed tweets: {len(df):,}\")\n",
    "print(f\"‚Ä¢ Unique users: {df['username'].nunique():,}\")\n",
    "print(f\"‚Ä¢ Unique hashtags: {len(hashtag_sentiment):,}\")\n",
    "print(f\"‚Ä¢ Average confidence score: {df['confidence'].mean():.3f}\")\n",
    "\n",
    "# Sentiment summary\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "total = len(df)\n",
    "\n",
    "print(\"\\nüòä SENTIMENT SUMMARY:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = (count / total) * 100\n",
    "    print(f\"‚Ä¢ {sentiment.capitalize()} sentiment: {percentage:.1f}% ({count:,} tweets)\")\n",
    "\n",
    "# Determine dominant sentiment and concern level\n",
    "neg_pct = (sentiment_counts.get('negative', 0) / total) * 100\n",
    "pos_pct = (sentiment_counts.get('positive', 0) / total) * 100\n",
    "\n",
    "if neg_pct > 50:\n",
    "    dominant_sentiment = \"NEGATIVE\"\n",
    "    concern_level = \"HIGH CONCERN\"\n",
    "elif pos_pct > 50:\n",
    "    dominant_sentiment = \"POSITIVE\"\n",
    "    concern_level = \"LOW CONCERN\"\n",
    "else:\n",
    "    dominant_sentiment = \"MIXED\"\n",
    "    concern_level = \"MODERATE CONCERN\"\n",
    "\n",
    "print(\"\\nüéØ KEY FINDINGS:\")\n",
    "print(f\"‚Ä¢ Dominant sentiment: {dominant_sentiment}\")\n",
    "print(f\"‚Ä¢ Public concern level: {concern_level}\")\n",
    "print(f\"‚Ä¢ Most mentioned hashtag: #{hashtag_df.iloc[0]['hashtag']} ({hashtag_df.iloc[0]['total']} mentions)\")\n",
    "print(f\"‚Ä¢ Economic-related tweets: {total_tweets_with_economic} ({economic_percentage:.1f}%)\")\n",
    "\n",
    "# Most active user\n",
    "most_active = user_stats.loc[user_stats['total_tweets'].idxmax()]\n",
    "print(f\"‚Ä¢ Most active user: @{most_active['username']} ({most_active['total_tweets']} tweets)\")\n",
    "\n",
    "print(\"\\nüí° RECOMMENDATIONS:\")\n",
    "if neg_pct > 50:\n",
    "    print(\"‚Ä¢ HIGH PRIORITY: Address underlying issues causing negative sentiment\")\n",
    "    print(\"‚Ä¢ Monitor economic impact on businesses, especially in protest areas\")\n",
    "    print(\"‚Ä¢ Engage with public concerns through dialogue and policy adjustments\")\n",
    "    print(\"‚Ä¢ Implement measures to minimize business disruption during protests\")\n",
    "elif pos_pct > 40:\n",
    "    print(\"‚Ä¢ Sentiment appears positive - continue current approach\")\n",
    "    print(\"‚Ä¢ Maintain open communication channels with the public\")\n",
    "else:\n",
    "    print(\"‚Ä¢ Mixed sentiment requires balanced approach\")\n",
    "    print(\"‚Ä¢ Focus on addressing specific concerns while maintaining stability\")\n",
    "    print(\"‚Ä¢ Monitor sentiment trends for early warning signs\")\n",
    "\n",
    "print(\"\\nüìà ECONOMIC IMPLICATIONS:\")\n",
    "print(\"‚Ä¢ Business closures during protest days impact local economy\")\n",
    "print(\"‚Ä¢ Negative sentiment may reduce consumer confidence and spending\")\n",
    "print(\"‚Ä¢ Tourism and investment may be affected by prolonged unrest\")\n",
    "print(\"‚Ä¢ Supply chain disruptions possible in affected areas\")\n",
    "print(\"‚Ä¢ Government should consider economic support for affected businesses\")\n",
    "\n",
    "print(\"\\nüîç METHODOLOGY:\")\n",
    "print(\"‚Ä¢ Sentiment analysis using Cardiff NLP Twitter XLM-RoBERTa model\")\n",
    "print(\"‚Ä¢ Three-class classification: Negative, Neutral, Positive\")\n",
    "print(\"‚Ä¢ Analysis includes hashtag patterns, user engagement, and economic terms\")\n",
    "print(\"‚Ä¢ Data sourced from Twitter using keywords related to Maandamano protests\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"               END OF REPORT\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps: Processing Remaining Tweets\n",
    "\n",
    "To complete the analysis, the remaining tweets in the dataset should be processed with the sentiment model. Use the following code to extend the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to process remaining tweets (requires transformer libraries)\n",
    "# This code shows how to extend the analysis to all tweets\n",
    "\n",
    "print(\"To process remaining tweets, run the following:\")\n",
    "print(\"1. Ensure all tweets are cleaned and preprocessed\")\n",
    "print(\"2. Run the sentiment labeling model on unlabeled tweets\")\n",
    "print(\"3. Combine with existing labeled data for complete analysis\")\n",
    "print(\"4. Update visualizations with complete dataset\")\n",
    "\n",
    "# Load raw tweet data to check what's remaining\n",
    "try:\n",
    "    raw_tweets = pd.read_csv('data/tweets.csv')\n",
    "    print(f\"\\nRaw tweets available: {len(raw_tweets)}\")\n",
    "    print(f\"Currently labeled: {len(df)}\")\n",
    "    print(f\"Remaining to process: {len(raw_tweets) - len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Raw tweets file not found\")\n",
    "\n",
    "# Sample code for processing (requires transformers library)\n",
    "sample_processing_code = '''\n",
    "# Sample code for processing remaining tweets\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Load model\n",
    "model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Process remaining tweets\n",
    "# ... (implement processing logic)\n",
    "'''\n",
    "\n",
    "print(\"\\nSample processing code (requires transformer libraries):\")\n",
    "print(sample_processing_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This comprehensive sentiment analysis of Maandamano Mondays data reveals significant insights into public opinion and potential economic impacts. The analysis shows a concerning level of negative sentiment that suggests high public concern about the issues driving the protests.\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **High Negative Sentiment**: Over 50% negative sentiment indicates significant public dissatisfaction\n",
    "2. **Economic Concerns**: Multiple tweets mention business and economic impacts\n",
    "3. **Widespread Engagement**: High user engagement across diverse demographics\n",
    "4. **Need for Action**: Results suggest urgent need to address underlying issues\n",
    "\n",
    "### Recommendations for Stakeholders:\n",
    "- **Government**: Address root causes of public concern through policy reforms\n",
    "- **Businesses**: Prepare contingency plans for protest periods\n",
    "- **Civil Society**: Facilitate constructive dialogue between parties\n",
    "- **Media**: Provide balanced coverage to avoid escalating tensions\n",
    "\n",
    "This analysis provides a data-driven foundation for understanding public sentiment and informing decision-making processes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
